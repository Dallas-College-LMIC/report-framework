# /rf-generate-report - Generate Report from Data Specification

## Purpose
Reads a data specification file and automatically generates and executes a Python script to collect data and produce a professional Excel report. Intelligently handles multiple data sources (Lightcast API via pyghtcast, Census data via censusdis) based on the specification requirements.

## Usage
```
/rf-generate-report <data_spec_path> [--dry-run]
```

**Parameters:**
- `data_spec_path`: Path to the data specification markdown file (e.g., `reports/2025-01-15_thomas-b_personal-training/data_spec.md`)
- `--dry-run`: (Optional) Generate the script but don't execute it

## Behavioral Instructions

### Core Workflow
When this command is invoked:

1. **Read and Parse Data Specification**
   - Read the markdown specification file
   - Extract all queries from the "Data Collection Queries" section
   - Identify required data sources, metrics, constraints, and geographic codes
   - Parse SOC codes, NAICS codes, MSA/FIPS codes, and other identifiers
   - Extract requestor information and output requirements

2. **Intelligent Data Source Detection**
   - **Lightcast Sources**: Identify datasets like `emsi.us.occupation`, `emsi.us.industry`, `emsi.us.staffing`
   - **Census Sources**: Identify ACS table references, demographic variables, Census API calls
     - Use context7 to understand how censusdis works
   - **Mixed Requirements**: Handle specifications requiring both data sources
   - Generate appropriate import statements and API setup code


3. **Generate Purpose-Built Python Script**
   Create a simple, executable Python script with:

   ```python
   #!/usr/bin/env python3
   """
   Auto-generated report script from data specification
   Generated by Claude Code rf-generate-report command
   """

   import os
   import pandas as pd
   import dclmic_export
   from datetime import datetime

   # Import data source libraries based on spec requirements
   # For Lightcast data:
   from pyghtcast.lightcast import Lightcast
   # For Census data:
   import censusdis
   ```

4. **Script Structure Requirements**
   - **Query Implementation**: One function per query defined in the spec
   - **Data Processing**: Implement any calculations specifically mentioned in the spec (growth rates, comparisons, etc.)
   - **Professional Formatting**: Round numeric data appropriately and handle data types correctly
   - **Professional Export**: Use dclmic_export.save_dfs_as_xl() with correct syntax
   - **CSV Export for Verification**: Export each DataFrame as CSV for Claude to read and verify data quality
   - **Friendly names**: Make column and table names easily understandable for non-technical stakeholders

5. **Execute Generated Script**
   - Write the script to the same directory as the data specification
   - Execute immediately (unless --dry-run flag is used)
   - Handle execution errors gracefully and provide clear feedback

### Data Source Implementation Patterns

#### Lightcast/pyghtcast Pattern
```python
# API Setup
lc = Lightcast(username=os.getenv('LCAPI_USER'), password=os.getenv('LCAPI_PASS'))

# Single area query implementation
def query_occupation_employment():
    cols = ["Jobs.2025", "Jobs.2030", "MeanEarnings.2025"]  # From spec
    constraints = [
        {
            "dimensionName": "Area",
            "map": {"Dallas-Fort Worth-Arlington, TX": ["MSA19100"]}  # Full area name: [area_code]
        },
        {
            "dimensionName": "Occupation",
            "map": {"Exercise Trainers and Group Fitness Instructors": ["39-9031"]}  # Full occupation title: [soc_code]
        }
    ]
    query = lc.build_query_corelmi(cols, constraints)
    return lc.query_corelmi('emsi.us.occupation', query, datarun='2025.3')

# Multiple area comparison query
def query_geographic_comparison():
    cols = ["Jobs.2025", "MeanEarnings.2025"]
    constraints = [
        {
            "dimensionName": "Area",
            "map": {
                "Dallas-Fort Worth-Arlington, TX": ["MSA19100"],
                "Houston-The Woodlands-Sugar Land, TX": ["MSA26420"],
                "Austin-Round Rock-Georgetown, TX": ["MSA12420"],
                "Texas": ["48"],
                "United States": ["US"]
            }
        },
        {
            "dimensionName": "Occupation",
            "map": {"Exercise Trainers and Group Fitness Instructors": ["39-9031"]}
        }
    ]
    query = lc.build_query_corelmi(cols, constraints)
    return lc.query_corelmi('emsi.us.occupation', query, datarun='2025.3')

# Industry constraint example
def query_industry_data():
    constraints = [
        {
            "dimensionName": "Area",
            "map": {"Dallas-Fort Worth-Arlington, TX": ["MSA19100"]}
        },
        {
            "dimensionName": "Industry",
            "map": {
                "Fitness and Recreational Sports Centers": ["713940"],
                "Sports and Recreation Instruction": ["611620"]
            }
        }
    ]
    # ... rest of query
```

#### Census/censusdis Pattern
```python
# Census data collection
import censusdis.data as ced

def query_demographic_data():
    # Implementation based on Census variables specified in spec
    df = ced.download(
        dataset="acs/acs5",
        vintage=2022,
        download_variables=["B01003_001E"],  # From spec
        state="48",  # Texas
        county="*"
    )
    return df
```

### Export Implementation
Always use dclmic_export for professional Excel output with correct syntax, and also export CSVs for data verification:

```python
def export_results():
    # Prepare data frames
    dataframes = [df1, df2, df3]  # From queries
    sheet_titles = [  # Note: sheet_titles, not sheet_names
        "Executive Summary",
        "Employment Data",
        "Wage Analysis",
        "Data Dictionary"
    ]

    file_name = f"{report_name}_{datetime.now().strftime('%Y%m%d')}"

    # Export using dclmic-export (note: .xlsx extension added automatically)
    dclmic_export.save_dfs_as_xl(
        list_of_frames=dataframes,
        path="./",  # Directory path (should end with /)
        file_name=file_name,  # No .xlsx extension needed
        sheet_titles=sheet_titles,  # Correct parameter name
    )

    print("ðŸ“„ Exporting CSV files for data verification...")
    for i, (df, sheet_title) in enumerate(zip(dataframes, sheet_titles)):
        csv_filename = f"{file_name}_{sheet_title.replace(' ', '_').lower()}.csv"
        df.to_csv(csv_filename, index=False)
        print(f"  âœ… {csv_filename}")
    print("âœ… CSV export complete - Claude can now read these files to verify data quality")
```

### File Management
- **Script Location**: Save generated script in same directory as data spec
- **Script Naming**: Use pattern `generate_{report_name}_report.py`
- **Output Location**: Place Excel file in same directory as data spec
- **CSV Files**: Export individual CSV files alongside Excel for Claude verification. Review the CSV files to ensure the data is correct.

### Quality Standards
- **Code Quality**: Generate clean, simple, readable Python code with appropriate comments. Keep it simple, stupid.
- **Data Processing**: Implement any calculations specified in the data spec accurately
- **Professional Output**: Use appropriate sheet names, formatting, and data organization
- **Documentation**: Include brief header comments explaining the script's purpose

## Example Generated Script Structure

```python
#!/usr/bin/env python3
"""
Personal Training Labor Market Analysis Report
Auto-generated from data_spec.md by Claude Code rf-generate-report
Generated: 2025-01-15
"""

import os
import pandas as pd
import dclmic_export
from datetime import datetime
from pyghtcast.lightcast import Lightcast

# API Setup
LC = Lightcast(username=os.getenv('LCAPI_USER'), password=os.getenv('LCAPI_PASS'))

def query_occupation_employment(lc):
    # Implementation based on Query 1 from spec
    pass

def query_industry_distribution(lc):
    # Implementation based on Query 2 from spec
    pass

def export_results(dataframes):
    # dclmic_export implementation
    pass

print("Starting report generation...")


# Execute queries
print("Collecting occupation data...")
df1 = query_occupation_employment(lc)

print("Collecting industry data...")
df2 = query_industry_distribution(lc)

# Export results
print("Generating Excel report and CSV files...")
export_results([df1, df2])

print("âœ… Report generation complete! Excel and CSV files created.")
```

## Integration Notes
- **Dependencies**: Uses existing project dependencies (pyghtcast, censusdis, dclmic-export, pandas)
- **Environment**: Assumes LCAPI_USER and LCAPI_PASS environment variables are set
- **File Structure**: Works with existing report folder structure from rf-create-report-spec
- **Compatibility**: Generated scripts are standalone and can be run independently

## Success Criteria
- Script generates without errors
- Script executes successfully and produces Excel output
- Excel file contains all data specified in the data spec
- CSV files are exported for each sheet allowing Claude to verify data quality
- Output is professional and ready for stakeholder review
- Process is efficient and user-friendly
- Data can be easily debugged via CSV inspection if issues arise
